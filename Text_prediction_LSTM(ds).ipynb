{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNT5Vg7XNDY7oEn01IjSF2s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HARDIK218/NLP-Task/blob/main/Text_prediction_LSTM(ds).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VH5rXFeKOL1T"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import text\n",
        "filename = \"/content/book(text prediction).txt\"\n",
        "raw_text = open(filename,'r',encoding = 'utf-8').read()\n",
        "raw_text = raw_text.lower()\n",
        "print(raw_text[0:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx_rqm_MPdbZ",
        "outputId": "fd36f1db-02bb-452d-ada4-8ccffb511da6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿the project gutenberg ebook of the jungle book\n",
            "    \n",
            "this ebook is for the use of anyone anywhere in the united states and\n",
            "most other parts of the world at no cost and with almost no restrictions\n",
            "whatsoever. you may copy it, give it away or re-use it under the terms\n",
            "of the project gutenberg license included with this ebook or online\n",
            "at www.gutenberg.org. if you are not located in the united states,\n",
            "you will have to check the laws of the country where you are located\n",
            "before using this ebook.\n",
            "\n",
            "title: the jungle book\n",
            "\n",
            "\n",
            "author: rudyard kipling\n",
            "\n",
            "release date: january 16, 2006 [ebook #236]\n",
            "                most recently updated: may 1, 2023\n",
            "\n",
            "language: english\n",
            "\n",
            "\n",
            "\n",
            "*** start of the project gutenberg ebook the jungle book ***\n",
            "\n",
            "\n",
            "\n",
            "the jungle book\n",
            "\n",
            "by rudyard kipling\n",
            "\n",
            "\n",
            "\n",
            "contents\n",
            "\n",
            "     mowgli’s brothers\n",
            "     hunting-song of the seeonee pack\n",
            "     kaa’s hunting\n",
            "     road-song of the bandar-log\n",
            "     “tiger! tiger!”\n",
            "      mowgli’s song\n",
            "     the white seal\n",
            "     lukannon\n",
            "     “rikki-tikki-tavi”\n",
            "      darze\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#clean text\n",
        "#remove number\n",
        "raw_text = ''.join(c for c in raw_text if not c.isdigit())\n",
        "\n",
        "char = sorted(list(set(raw_text)))#list of every character\n"
      ],
      "metadata": {
        "id": "thSWqgBxPmag"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E2C0BWRTo3S",
        "outputId": "3ba5a85c-952b-4868-8986-e65d5e3c95d7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " ' ',\n",
              " '!',\n",
              " '#',\n",
              " '$',\n",
              " '%',\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '[',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " 'â',\n",
              " '—',\n",
              " '‘',\n",
              " '’',\n",
              " '“',\n",
              " '”',\n",
              " '•',\n",
              " '™',\n",
              " '\\ufeff']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convert it to integers,each unique value will be assigned an integer\n",
        "#create a dictionary of characters mapped to integer value\n",
        "char_to_int = dict((c,i) for i,c in enumerate(char))\n",
        "\n",
        "#do reverse so that we print character not in integer\n",
        "int_to_char = dict((i,c) for i,c in enumerate(char))"
      ],
      "metadata": {
        "id": "CxoSbB1lTp_i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#summarize the data\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(char)\n",
        "print(\"total char in the text\",n_chars)\n",
        "print(\"total vocab\" , n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MPJoNOCUi5s",
        "outputId": "3b1741df-a71c-4b49-bded-7958a5a1e472"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total char in the text 292119\n",
            "total vocab 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#now we will craete input and output sequence for training\n",
        "\n",
        "seq_length = 60\n",
        "step = 10\n",
        "sentences = [] #x values(sentences)\n",
        "next_chars = [] #y value the character that follows the sentence defined as x\n",
        "for i in range(0,n_chars-seq_length,step):\n",
        "  sentences.append(raw_text[i:i+seq_length]) #step=1 means each sentence is offset just by single letter\n",
        "  next_chars.append(raw_text[i+seq_length])\n",
        "n_patterns = len(sentences)\n",
        "print('number of sequences',n_patterns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Vm5cwiU8Dj",
        "outputId": "3b6d092c-050f-4758-f5f2-73b743ca17c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of sequences 29206\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reshape input to be [samples, time steps, features]\n",
        "\n",
        "#time steps = sequence length\n",
        "#features = numbers of characters in our vocab (n_vocab)\n",
        "#Vectorize all sentences: there are n_patterns sentences.\n",
        "#For each sentence we have n_vocab characters available for seq_length\n",
        "#Vectorization returns a vector for all sentences indicating the presence or absence\n",
        "#of a character.\n",
        "\n",
        "x = np.zeros((len(sentences),seq_length,n_vocab),dtype=np.bool)\n",
        "y = np.zeros((len(sentences),n_vocab),dtype=np.bool)\n",
        "for i,sentence in enumerate(sentences):\n",
        "  for t,char in enumerate(sentence):\n",
        "    x[i,t,char_to_int[char]] = 1\n",
        "    y[i,char_to_int[next_chars[i]]] = 1\n",
        "\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(y[0:10])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B9B3fa1Ys8-",
        "outputId": "080b9d8b-e52c-4fbd-d6e9-d3dbb6cce591"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-f086c95888d0>:10: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x = np.zeros((len(sentences),seq_length,n_vocab),dtype=np.bool)\n",
            "<ipython-input-11-f086c95888d0>:11: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y = np.zeros((len(sentences),n_vocab),dtype=np.bool)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29206, 60, 55)\n",
            "(29206, 55)\n",
            "[[False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False  True False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False  True False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False  True False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False  True\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False  True False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False  True False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False False False False  True False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]\n",
            " [False False False False False False False False False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False  True False False False False\n",
            "  False False False False False False False False False False False False\n",
            "  False False False False False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#building the model\n",
        "#we add return_sequences true as it gives 1st lstm out to the second lstm\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(seq_length, n_vocab), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_vocab, activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhwQ9R4qbVjf",
        "outputId": "14788b81-123e-43dd-8260-95c508cd4f3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 60, 128)           94208     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 60, 128)           0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 128)               131584    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 55)                7095      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 232887 (909.71 KB)\n",
            "Trainable params: 232887 (909.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the checkpoint\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"saved_weights/saved_weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "\n",
        "# Fit the model\n",
        "\n",
        "history = model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=50,\n",
        "          callbacks=callbacks_list)\n",
        "\n",
        "model.save('my_saved_weights_jungle_book_50epochs.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8sySyQgcnsf",
        "outputId": "0c31f445-668e-4d92-e616-8be8bd582c61"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 2.0602\n",
            "Epoch 1: loss improved from inf to 2.05919, saving model to saved_weights/saved_weights-01-2.0592.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 2.0592\n",
            "Epoch 2/50\n",
            " 16/229 [=>............................] - ETA: 2s - loss: 2.0647"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "226/229 [============================>.] - ETA: 0s - loss: 2.0235\n",
            "Epoch 2: loss improved from 2.05919 to 2.02278, saving model to saved_weights/saved_weights-02-2.0228.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 2.0228\n",
            "Epoch 3/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.9893\n",
            "Epoch 3: loss improved from 2.02278 to 1.98928, saving model to saved_weights/saved_weights-03-1.9893.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.9893\n",
            "Epoch 4/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.9555\n",
            "Epoch 4: loss improved from 1.98928 to 1.95450, saving model to saved_weights/saved_weights-04-1.9545.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.9545\n",
            "Epoch 5/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.9229\n",
            "Epoch 5: loss improved from 1.95450 to 1.92328, saving model to saved_weights/saved_weights-05-1.9233.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.9233\n",
            "Epoch 6/50\n",
            "224/229 [============================>.] - ETA: 0s - loss: 1.8896\n",
            "Epoch 6: loss improved from 1.92328 to 1.88956, saving model to saved_weights/saved_weights-06-1.8896.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.8896\n",
            "Epoch 7/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.8661\n",
            "Epoch 7: loss improved from 1.88956 to 1.86549, saving model to saved_weights/saved_weights-07-1.8655.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.8655\n",
            "Epoch 8/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.8354\n",
            "Epoch 8: loss improved from 1.86549 to 1.83584, saving model to saved_weights/saved_weights-08-1.8358.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.8358\n",
            "Epoch 9/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.8131\n",
            "Epoch 9: loss improved from 1.83584 to 1.81329, saving model to saved_weights/saved_weights-09-1.8133.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.8133\n",
            "Epoch 10/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.7847\n",
            "Epoch 10: loss improved from 1.81329 to 1.78466, saving model to saved_weights/saved_weights-10-1.7847.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.7847\n",
            "Epoch 11/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.7582\n",
            "Epoch 11: loss improved from 1.78466 to 1.75745, saving model to saved_weights/saved_weights-11-1.7575.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.7575\n",
            "Epoch 12/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.7320\n",
            "Epoch 12: loss improved from 1.75745 to 1.73345, saving model to saved_weights/saved_weights-12-1.7334.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.7334\n",
            "Epoch 13/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.7109\n",
            "Epoch 13: loss improved from 1.73345 to 1.70913, saving model to saved_weights/saved_weights-13-1.7091.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.7091\n",
            "Epoch 14/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.6879\n",
            "Epoch 14: loss improved from 1.70913 to 1.68789, saving model to saved_weights/saved_weights-14-1.6879.hdf5\n",
            "229/229 [==============================] - 5s 22ms/step - loss: 1.6879\n",
            "Epoch 15/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.6631\n",
            "Epoch 15: loss improved from 1.68789 to 1.66259, saving model to saved_weights/saved_weights-15-1.6626.hdf5\n",
            "229/229 [==============================] - 4s 17ms/step - loss: 1.6626\n",
            "Epoch 16/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.6437\n",
            "Epoch 16: loss improved from 1.66259 to 1.64309, saving model to saved_weights/saved_weights-16-1.6431.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.6431\n",
            "Epoch 17/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.6166\n",
            "Epoch 17: loss improved from 1.64309 to 1.61714, saving model to saved_weights/saved_weights-17-1.6171.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.6171\n",
            "Epoch 18/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.5925\n",
            "Epoch 18: loss improved from 1.61714 to 1.59478, saving model to saved_weights/saved_weights-18-1.5948.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.5948\n",
            "Epoch 19/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.5737\n",
            "Epoch 19: loss improved from 1.59478 to 1.57375, saving model to saved_weights/saved_weights-19-1.5737.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.5737\n",
            "Epoch 20/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.5505\n",
            "Epoch 20: loss improved from 1.57375 to 1.55077, saving model to saved_weights/saved_weights-20-1.5508.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.5508\n",
            "Epoch 21/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.5232\n",
            "Epoch 21: loss improved from 1.55077 to 1.52323, saving model to saved_weights/saved_weights-21-1.5232.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.5232\n",
            "Epoch 22/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.5043\n",
            "Epoch 22: loss improved from 1.52323 to 1.50489, saving model to saved_weights/saved_weights-22-1.5049.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.5049\n",
            "Epoch 23/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.4766\n",
            "Epoch 23: loss improved from 1.50489 to 1.47715, saving model to saved_weights/saved_weights-23-1.4771.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.4771\n",
            "Epoch 24/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.4602\n",
            "Epoch 24: loss improved from 1.47715 to 1.46101, saving model to saved_weights/saved_weights-24-1.4610.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.4610\n",
            "Epoch 25/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.4374\n",
            "Epoch 25: loss improved from 1.46101 to 1.43808, saving model to saved_weights/saved_weights-25-1.4381.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.4381\n",
            "Epoch 26/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.4075\n",
            "Epoch 26: loss improved from 1.43808 to 1.40754, saving model to saved_weights/saved_weights-26-1.4075.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.4075\n",
            "Epoch 27/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.3854\n",
            "Epoch 27: loss improved from 1.40754 to 1.38536, saving model to saved_weights/saved_weights-27-1.3854.hdf5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 1.3854\n",
            "Epoch 28/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.3648\n",
            "Epoch 28: loss improved from 1.38536 to 1.36480, saving model to saved_weights/saved_weights-28-1.3648.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.3648\n",
            "Epoch 29/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.3459\n",
            "Epoch 29: loss improved from 1.36480 to 1.34566, saving model to saved_weights/saved_weights-29-1.3457.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.3457\n",
            "Epoch 30/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.3197\n",
            "Epoch 30: loss improved from 1.34566 to 1.31981, saving model to saved_weights/saved_weights-30-1.3198.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.3198\n",
            "Epoch 31/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.3065\n",
            "Epoch 31: loss improved from 1.31981 to 1.30656, saving model to saved_weights/saved_weights-31-1.3066.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.3066\n",
            "Epoch 32/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.2813\n",
            "Epoch 32: loss improved from 1.30656 to 1.28059, saving model to saved_weights/saved_weights-32-1.2806.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.2806\n",
            "Epoch 33/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.2590\n",
            "Epoch 33: loss improved from 1.28059 to 1.25891, saving model to saved_weights/saved_weights-33-1.2589.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.2589\n",
            "Epoch 34/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 1.2317\n",
            "Epoch 34: loss improved from 1.25891 to 1.23240, saving model to saved_weights/saved_weights-34-1.2324.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.2324\n",
            "Epoch 35/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.2150\n",
            "Epoch 35: loss improved from 1.23240 to 1.21507, saving model to saved_weights/saved_weights-35-1.2151.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.2151\n",
            "Epoch 36/50\n",
            "229/229 [==============================] - ETA: 0s - loss: 1.1962\n",
            "Epoch 36: loss improved from 1.21507 to 1.19621, saving model to saved_weights/saved_weights-36-1.1962.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.1962\n",
            "Epoch 37/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.1720\n",
            "Epoch 37: loss improved from 1.19621 to 1.17201, saving model to saved_weights/saved_weights-37-1.1720.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.1720\n",
            "Epoch 38/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.1558\n",
            "Epoch 38: loss improved from 1.17201 to 1.15556, saving model to saved_weights/saved_weights-38-1.1556.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.1556\n",
            "Epoch 39/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 1.1297\n",
            "Epoch 39: loss improved from 1.15556 to 1.12944, saving model to saved_weights/saved_weights-39-1.1294.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.1294\n",
            "Epoch 40/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.1087\n",
            "Epoch 40: loss improved from 1.12944 to 1.10948, saving model to saved_weights/saved_weights-40-1.1095.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.1095\n",
            "Epoch 41/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.0876\n",
            "Epoch 41: loss improved from 1.10948 to 1.08768, saving model to saved_weights/saved_weights-41-1.0877.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.0877\n",
            "Epoch 42/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 1.0781\n",
            "Epoch 42: loss improved from 1.08768 to 1.07826, saving model to saved_weights/saved_weights-42-1.0783.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.0783\n",
            "Epoch 43/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.0514\n",
            "Epoch 43: loss improved from 1.07826 to 1.05162, saving model to saved_weights/saved_weights-43-1.0516.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 1.0516\n",
            "Epoch 44/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.0348\n",
            "Epoch 44: loss improved from 1.05162 to 1.03481, saving model to saved_weights/saved_weights-44-1.0348.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 1.0348\n",
            "Epoch 45/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 1.0162\n",
            "Epoch 45: loss improved from 1.03481 to 1.01606, saving model to saved_weights/saved_weights-45-1.0161.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 1.0161\n",
            "Epoch 46/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 0.9965\n",
            "Epoch 46: loss improved from 1.01606 to 0.99731, saving model to saved_weights/saved_weights-46-0.9973.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 0.9973\n",
            "Epoch 47/50\n",
            "225/229 [============================>.] - ETA: 0s - loss: 0.9818\n",
            "Epoch 47: loss improved from 0.99731 to 0.98222, saving model to saved_weights/saved_weights-47-0.9822.hdf5\n",
            "229/229 [==============================] - 3s 14ms/step - loss: 0.9822\n",
            "Epoch 48/50\n",
            "228/229 [============================>.] - ETA: 0s - loss: 0.9663\n",
            "Epoch 48: loss improved from 0.98222 to 0.96639, saving model to saved_weights/saved_weights-48-0.9664.hdf5\n",
            "229/229 [==============================] - 3s 11ms/step - loss: 0.9664\n",
            "Epoch 49/50\n",
            "227/229 [============================>.] - ETA: 0s - loss: 0.9494\n",
            "Epoch 49: loss improved from 0.96639 to 0.94962, saving model to saved_weights/saved_weights-49-0.9496.hdf5\n",
            "229/229 [==============================] - 3s 12ms/step - loss: 0.9496\n",
            "Epoch 50/50\n",
            "226/229 [============================>.] - ETA: 0s - loss: 0.9285\n",
            "Epoch 50: loss improved from 0.94962 to 0.92802, saving model to saved_weights/saved_weights-50-0.9280.hdf5\n",
            "229/229 [==============================] - 3s 13ms/step - loss: 0.9280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "klScBHGYdNXE",
        "outputId": "87809377-fc8f-4f02-fb25-429fbc743971"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We must provide a sequence of seq_lenth as input to start the generation process\n",
        "\n",
        "#The prediction results is probabilities for each of the 48 characters at a specific\n",
        "#point in sequence. Let us pick the one with max probability and print it out.\n",
        "#Writing our own softmax function....\n",
        "\n",
        "def sample(preds):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds) #exp of log (x), isn't this same as x??\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n"
      ],
      "metadata": {
        "id": "lRtEguN7d2EV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction\n",
        "# load the network weights\n",
        "filename = \"my_saved_weights_jungle_book_50epochs.h5\"\n",
        "model.load_weights(filename)\n",
        "\n",
        "#Pick a random sentence from the text as seed.\n",
        "start_index = random.randint(0, n_chars - seq_length - 1)\n",
        "\n",
        "#Initiate generated text and keep adding new predictions and print them out\n",
        "generated = ''\n",
        "sentence = raw_text[start_index: start_index + seq_length]\n",
        "generated += sentence\n",
        "\n",
        "print('----- Seed for our text prediction: \"' + sentence + '\"')\n",
        "#sys.stdout.write(generated)\n",
        "\n",
        "\n",
        "for i in range(400):   # Number of characters including spaces\n",
        "    x_pred = np.zeros((1, seq_length, n_vocab))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_to_int[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds)\n",
        "    next_char = int_to_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n",
        "print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUQBPygfd8Iu",
        "outputId": "5e305b9a-9a85-4cfa-e7e4-b97900f4b43e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Seed for our text prediction: \"f the fight round the black panther--the\n",
            "yells and chatterin\"\n",
            "g male pouth the ter lock. the head:\n",
            "uf i his saitighoss and pack and growntion in troen, the feaths on the his look n; the fright prone to that eye god\n",
            "we have as big sere the mach spere the conrasing of the till\n",
            "grat norgions the see by the inderss in their never go fot the tood toution the tillled brownd himssithered the tong gamw the clops of the said begween steace till thee water#onf wer lit\n"
          ]
        }
      ]
    }
  ]
}